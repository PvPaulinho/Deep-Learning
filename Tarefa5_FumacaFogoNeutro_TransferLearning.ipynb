{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarefa5_FumacaFogoNeutro_TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PvPaulinho/Deep-Learning-Facul-/blob/main/Tarefa5_FumacaFogoNeutro_TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jMG8Lrgd4on"
      },
      "source": [
        "# Tarefa 5\n",
        "\n",
        "Nesta tarefa, utilizaremos novamente o banco de imagens para detecção de fumaça e fogo. \n",
        "\n",
        "Desta vez, vamos usar Transfer Learning para melhorar o desempenho do classificador. \n",
        "\n",
        "O dataset foi disponibilizado por [Kaiming H. et al, Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385 ). \n",
        "\n",
        "Os arquivos estão dispostos na mesma estrutura da Tarefa 4. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEDvwgLzgLvN"
      },
      "source": [
        "## Questões\n",
        "\n",
        "1. Crie 2 modelos, um para o conjunto N-F e outro para o conjunto N-S. Através de TransferLearning, utilize parte da rede pré-treinada da InceptionV3 (conforme a Lição 9). Avalie o desempenho (acurácia e perdas no treinamento e validação). \n",
        "\n",
        "2. Desenvolva um classificador categórico, com a InceptionV3, para discriminar os 3 tipos de imagem: Neutro, Fumaça e Fogo. Avalie o desempenho. Você deverá modificar alguns pontos na sua rede, para que o classificador seja categórico: (i) flow_from_directory, (ii) função de perda e (iii) número de neurônios na camada de saída. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIET52LYfk9Y"
      },
      "source": [
        "O conjunto Neutro-Fogo está no diretório `/tmp/N-F/` e o conjunto Neutro-Fumaça está em `/tmp/N-S/`. \n",
        "\n",
        "O conjunto completo (com as três classes, Neutro, Fumaça e Fogo) está em `/tmp/FIRE-SMOKE/DATASET/`. \n",
        "\n",
        "Cada conjunto tem 2 subconjuntos: `Train` e `Test` para treinamento e validação, respectivamente. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NFuMFYXtwsT",
        "outputId": "070a6564-38a9-4b7a-ea62-7371e2cf553b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras import regularizers, optimizers\n",
        "\n",
        "DESIRED_ACCURACY = 0.99\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/DeepQuestAI/Fire-Smoke-Dataset/releases/download/v1/FIRE-SMOKE-DATASET.zip\" -O \"/tmp/fire-smoke.zip\"\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/tmp/fire-smoke.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/\")\n",
        "zip_ref.close()\n",
        "\n",
        "# Conjunto Fumaça-Fogo\n",
        "!mkdir -p /tmp/S-F/{Train,Test}/\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Smoke\" \"/tmp/S-F/Train/Smoke\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Smoke\" \"/tmp/S-F/Test/Smoke\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Fire\" \"/tmp/S-F/Train/Fire\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Fire\" \"/tmp/S-F/Test/Fire\"\n",
        "\n",
        "# Conjunto Neutro-Fogo\n",
        "!mkdir -p /tmp/N-F/{Train,Test}/\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Neutral\" \"/tmp/N-F/Train/Neutral\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Neutral\" \"/tmp/N-F/Test/Neutral\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Fire\" \"/tmp/N-F/Train/Fire\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Fire\" \"/tmp/N-F/Test/Fire\"\n",
        "\n",
        "# Conjunto Neutro-Fumaça\n",
        "!mkdir -p /tmp/N-S/{Train,Test}/\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Neutral\" \"/tmp/N-S/Train/Neutral\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Neutral\" \"/tmp/N-S/Test/Neutral\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Smoke\" \"/tmp/N-S/Train/Smoke\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Smoke\" \"/tmp/N-S/Test/Smoke\"\n",
        "\n",
        "base_dir = '/tmp/N-F'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "\n",
        "train_Fire_dir = os.path.join(train_dir, 'Fire')\n",
        "train_Neutral_dir = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "\n",
        "validation_Fire_dir = os.path.join(validation_dir, 'Fire')\n",
        "validation_Neutral_dir = os.path.join(validation_dir, 'Neutral')\n",
        "\n",
        "weight_decay = 1e-4 \n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    steps_per_epoch=90,\n",
        "                    epochs=15,\n",
        "                    validation_steps=10,\n",
        "                    verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-29 23:36:11--  https://github.com/DeepQuestAI/Fire-Smoke-Dataset/releases/download/v1/FIRE-SMOKE-DATASET.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/193940929/09220a00-9842-11e9-8756-2d8df8631bb5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211129T233612Z&X-Amz-Expires=300&X-Amz-Signature=cf984728a1f8cff29012ff4ab4c04bde72403f6e90ec49def18a9f666719f67d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=193940929&response-content-disposition=attachment%3B%20filename%3DFIRE-SMOKE-DATASET.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-11-29 23:36:12--  https://github-releases.githubusercontent.com/193940929/09220a00-9842-11e9-8756-2d8df8631bb5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211129T233612Z&X-Amz-Expires=300&X-Amz-Signature=cf984728a1f8cff29012ff4ab4c04bde72403f6e90ec49def18a9f666719f67d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=193940929&response-content-disposition=attachment%3B%20filename%3DFIRE-SMOKE-DATASET.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.110.154, 185.199.108.154, 185.199.111.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.110.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 320963592 (306M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/fire-smoke.zip’\n",
            "\n",
            "/tmp/fire-smoke.zip 100%[===================>] 306.09M  78.3MB/s    in 3.9s    \n",
            "\n",
            "2021-11-29 23:36:16 (79.2 MB/s) - ‘/tmp/fire-smoke.zip’ saved [320963592/320963592]\n",
            "\n",
            "Found 1800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Epoch 1/15\n",
            "90/90 - 22s - loss: 0.5935 - accuracy: 0.8039 - val_loss: 0.9532 - val_accuracy: 0.5000 - 22s/epoch - 247ms/step\n",
            "Epoch 2/15\n",
            "90/90 - 20s - loss: 0.4302 - accuracy: 0.8500 - val_loss: 1.8097 - val_accuracy: 0.5000 - 20s/epoch - 220ms/step\n",
            "Epoch 3/15\n",
            "90/90 - 20s - loss: 0.4231 - accuracy: 0.8567 - val_loss: 3.3606 - val_accuracy: 0.5000 - 20s/epoch - 220ms/step\n",
            "Epoch 4/15\n",
            "90/90 - 20s - loss: 0.3398 - accuracy: 0.8872 - val_loss: 1.4439 - val_accuracy: 0.5250 - 20s/epoch - 218ms/step\n",
            "Epoch 5/15\n",
            "90/90 - 19s - loss: 0.3192 - accuracy: 0.9000 - val_loss: 0.7931 - val_accuracy: 0.7550 - 19s/epoch - 214ms/step\n",
            "Epoch 6/15\n",
            "90/90 - 19s - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.4610 - val_accuracy: 0.8550 - 19s/epoch - 211ms/step\n",
            "Epoch 7/15\n",
            "90/90 - 19s - loss: 0.2775 - accuracy: 0.9111 - val_loss: 0.2827 - val_accuracy: 0.9000 - 19s/epoch - 210ms/step\n",
            "Epoch 8/15\n",
            "90/90 - 19s - loss: 0.2440 - accuracy: 0.9239 - val_loss: 0.4322 - val_accuracy: 0.8600 - 19s/epoch - 208ms/step\n",
            "Epoch 9/15\n",
            "90/90 - 19s - loss: 0.2733 - accuracy: 0.9144 - val_loss: 0.3420 - val_accuracy: 0.9200 - 19s/epoch - 208ms/step\n",
            "Epoch 10/15\n",
            "90/90 - 19s - loss: 0.2393 - accuracy: 0.9322 - val_loss: 0.2913 - val_accuracy: 0.9200 - 19s/epoch - 208ms/step\n",
            "Epoch 11/15\n",
            "90/90 - 19s - loss: 0.2413 - accuracy: 0.9250 - val_loss: 0.5342 - val_accuracy: 0.8650 - 19s/epoch - 208ms/step\n",
            "Epoch 12/15\n",
            "90/90 - 19s - loss: 0.2149 - accuracy: 0.9367 - val_loss: 0.4758 - val_accuracy: 0.8850 - 19s/epoch - 207ms/step\n",
            "Epoch 13/15\n",
            "90/90 - 19s - loss: 0.2162 - accuracy: 0.9306 - val_loss: 0.4475 - val_accuracy: 0.8650 - 19s/epoch - 207ms/step\n",
            "Epoch 14/15\n",
            "90/90 - 19s - loss: 0.2369 - accuracy: 0.9311 - val_loss: 0.3745 - val_accuracy: 0.9100 - 19s/epoch - 207ms/step\n",
            "Epoch 15/15\n",
            "90/90 - 19s - loss: 0.2187 - accuracy: 0.9344 - val_loss: 0.4102 - val_accuracy: 0.9000 - 19s/epoch - 207ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9fggMgC8VdV",
        "outputId": "f977ac8a-2b29-40d4-dd6c-18dfee8cdd71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_dir = '/tmp/N-S'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "\n",
        "train_Fire_dir = os.path.join(train_dir, 'Smoke')\n",
        "train_Neutral_dir = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "\n",
        "validation_Fire_dir = os.path.join(validation_dir, 'Smoke')\n",
        "validation_Neutral_dir = os.path.join(validation_dir, 'Neutral')\n",
        "\n",
        "weight_decay = 1e-4 \n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    steps_per_epoch=90,\n",
        "                    epochs=15,\n",
        "                    validation_steps=10,\n",
        "                    verbose=2)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Epoch 1/15\n",
            "90/90 - 21s - loss: 0.8752 - accuracy: 0.7094 - val_loss: 0.7823 - val_accuracy: 0.5000 - 21s/epoch - 228ms/step\n",
            "Epoch 2/15\n",
            "90/90 - 18s - loss: 0.7176 - accuracy: 0.7494 - val_loss: 1.8307 - val_accuracy: 0.5000 - 18s/epoch - 202ms/step\n",
            "Epoch 3/15\n",
            "90/90 - 18s - loss: 0.6424 - accuracy: 0.7656 - val_loss: 1.0287 - val_accuracy: 0.5100 - 18s/epoch - 201ms/step\n",
            "Epoch 4/15\n",
            "90/90 - 18s - loss: 0.6001 - accuracy: 0.7667 - val_loss: 1.0348 - val_accuracy: 0.5950 - 18s/epoch - 201ms/step\n",
            "Epoch 5/15\n",
            "90/90 - 18s - loss: 0.6062 - accuracy: 0.7583 - val_loss: 0.8908 - val_accuracy: 0.6700 - 18s/epoch - 202ms/step\n",
            "Epoch 6/15\n",
            "90/90 - 18s - loss: 0.5727 - accuracy: 0.7667 - val_loss: 0.6098 - val_accuracy: 0.7500 - 18s/epoch - 200ms/step\n",
            "Epoch 7/15\n",
            "90/90 - 18s - loss: 0.5398 - accuracy: 0.7806 - val_loss: 0.6481 - val_accuracy: 0.7400 - 18s/epoch - 201ms/step\n",
            "Epoch 8/15\n",
            "90/90 - 18s - loss: 0.5329 - accuracy: 0.7844 - val_loss: 0.4856 - val_accuracy: 0.7850 - 18s/epoch - 202ms/step\n",
            "Epoch 9/15\n",
            "90/90 - 18s - loss: 0.5095 - accuracy: 0.7867 - val_loss: 0.5523 - val_accuracy: 0.7400 - 18s/epoch - 201ms/step\n",
            "Epoch 10/15\n",
            "90/90 - 18s - loss: 0.4742 - accuracy: 0.8100 - val_loss: 0.5373 - val_accuracy: 0.7600 - 18s/epoch - 200ms/step\n",
            "Epoch 11/15\n",
            "90/90 - 18s - loss: 0.4749 - accuracy: 0.7939 - val_loss: 0.9114 - val_accuracy: 0.6650 - 18s/epoch - 201ms/step\n",
            "Epoch 12/15\n",
            "90/90 - 18s - loss: 0.4944 - accuracy: 0.8056 - val_loss: 0.4280 - val_accuracy: 0.8350 - 18s/epoch - 200ms/step\n",
            "Epoch 13/15\n",
            "90/90 - 18s - loss: 0.4569 - accuracy: 0.8239 - val_loss: 0.5028 - val_accuracy: 0.7650 - 18s/epoch - 200ms/step\n",
            "Epoch 14/15\n",
            "90/90 - 18s - loss: 0.4522 - accuracy: 0.8133 - val_loss: 0.4651 - val_accuracy: 0.8100 - 18s/epoch - 200ms/step\n",
            "Epoch 15/15\n",
            "90/90 - 18s - loss: 0.4750 - accuracy: 0.8178 - val_loss: 0.5452 - val_accuracy: 0.8000 - 18s/epoch - 204ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qGVaoov-bPs",
        "outputId": "be26a9b8-fe91-4f57-93a1-b4170779fbe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_dir = '/tmp/N-F'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "\n",
        "train_Fire_dir = os.path.join(train_dir, 'Fire')\n",
        "train_Neutral_dir = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "\n",
        "validation_Fire_dir = os.path.join(validation_dir, 'Fire')\n",
        "validation_Neutral_dir = os.path.join(validation_dir, 'Neutral')\n",
        "\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 90,\n",
        "            epochs = 20,\n",
        "            validation_steps = 10,\n",
        "            verbose = 2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-29 23:45:47--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.181.128, 173.194.195.128, 173.194.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.181.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  34.2MB/s    in 2.5s    \n",
            "\n",
            "2021-11-29 23:45:50 (34.2 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 7, 7, 768)\n",
            "Found 1800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "90/90 - 25s - loss: 0.2477 - accuracy: 0.9122 - val_loss: 0.1505 - val_accuracy: 0.9600 - 25s/epoch - 283ms/step\n",
            "Epoch 2/20\n",
            "90/90 - 20s - loss: 0.1054 - accuracy: 0.9639 - val_loss: 0.1875 - val_accuracy: 0.9500 - 20s/epoch - 221ms/step\n",
            "Epoch 3/20\n",
            "90/90 - 20s - loss: 0.0804 - accuracy: 0.9772 - val_loss: 0.2253 - val_accuracy: 0.9650 - 20s/epoch - 217ms/step\n",
            "Epoch 4/20\n",
            "90/90 - 20s - loss: 0.0889 - accuracy: 0.9711 - val_loss: 0.2076 - val_accuracy: 0.9700 - 20s/epoch - 221ms/step\n",
            "Epoch 5/20\n",
            "90/90 - 19s - loss: 0.0468 - accuracy: 0.9783 - val_loss: 0.2656 - val_accuracy: 0.9700 - 19s/epoch - 212ms/step\n",
            "Epoch 6/20\n",
            "90/90 - 19s - loss: 0.0778 - accuracy: 0.9789 - val_loss: 0.2678 - val_accuracy: 0.9600 - 19s/epoch - 214ms/step\n",
            "Epoch 7/20\n",
            "90/90 - 20s - loss: 0.0554 - accuracy: 0.9794 - val_loss: 0.3588 - val_accuracy: 0.9600 - 20s/epoch - 222ms/step\n",
            "Epoch 8/20\n",
            "90/90 - 19s - loss: 0.0791 - accuracy: 0.9783 - val_loss: 0.3146 - val_accuracy: 0.9650 - 19s/epoch - 216ms/step\n",
            "Epoch 9/20\n",
            "90/90 - 20s - loss: 0.0722 - accuracy: 0.9783 - val_loss: 0.3406 - val_accuracy: 0.9600 - 20s/epoch - 221ms/step\n",
            "Epoch 10/20\n",
            "90/90 - 20s - loss: 0.0712 - accuracy: 0.9789 - val_loss: 0.3872 - val_accuracy: 0.9500 - 20s/epoch - 217ms/step\n",
            "Epoch 11/20\n",
            "90/90 - 20s - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.3447 - val_accuracy: 0.9550 - 20s/epoch - 217ms/step\n",
            "Epoch 12/20\n",
            "90/90 - 20s - loss: 0.0559 - accuracy: 0.9828 - val_loss: 0.4056 - val_accuracy: 0.9550 - 20s/epoch - 217ms/step\n",
            "Epoch 13/20\n",
            "90/90 - 19s - loss: 0.0779 - accuracy: 0.9783 - val_loss: 0.3791 - val_accuracy: 0.9600 - 19s/epoch - 216ms/step\n",
            "Epoch 14/20\n",
            "90/90 - 20s - loss: 0.0435 - accuracy: 0.9894 - val_loss: 0.4457 - val_accuracy: 0.9600 - 20s/epoch - 223ms/step\n",
            "Epoch 15/20\n",
            "90/90 - 19s - loss: 0.0674 - accuracy: 0.9828 - val_loss: 0.3409 - val_accuracy: 0.9700 - 19s/epoch - 214ms/step\n",
            "Epoch 16/20\n",
            "90/90 - 19s - loss: 0.0740 - accuracy: 0.9828 - val_loss: 0.3980 - val_accuracy: 0.9600 - 19s/epoch - 216ms/step\n",
            "Epoch 17/20\n",
            "90/90 - 19s - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.4137 - val_accuracy: 0.9600 - 19s/epoch - 216ms/step\n",
            "Epoch 18/20\n",
            "90/90 - 19s - loss: 0.0547 - accuracy: 0.9844 - val_loss: 0.3855 - val_accuracy: 0.9700 - 19s/epoch - 213ms/step\n",
            "Epoch 19/20\n",
            "90/90 - 20s - loss: 0.0483 - accuracy: 0.9861 - val_loss: 0.3338 - val_accuracy: 0.9700 - 20s/epoch - 221ms/step\n",
            "Epoch 20/20\n",
            "90/90 - 19s - loss: 0.0604 - accuracy: 0.9856 - val_loss: 0.3450 - val_accuracy: 0.9750 - 19s/epoch - 213ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miW6v5cyA2JB",
        "outputId": "ba8ed334-93a4-45d0-c9b5-0cc7fad67fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_dir = '/tmp/N-S'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "\n",
        "train_Fire_dir = os.path.join(train_dir, 'Smoke')\n",
        "train_Neutral_dir = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "\n",
        "validation_Fire_dir = os.path.join(validation_dir, 'Smoke')\n",
        "validation_Neutral_dir = os.path.join(validation_dir, 'Neutral')\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 90,\n",
        "            epochs = 20,\n",
        "            validation_steps = 10,\n",
        "            verbose = 2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n",
            "Found 1800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "90/90 - 25s - loss: 0.3635 - accuracy: 0.8472 - val_loss: 0.1194 - val_accuracy: 0.9550 - 25s/epoch - 277ms/step\n",
            "Epoch 2/20\n",
            "90/90 - 20s - loss: 0.1844 - accuracy: 0.9306 - val_loss: 0.3635 - val_accuracy: 0.8800 - 20s/epoch - 217ms/step\n",
            "Epoch 3/20\n",
            "90/90 - 19s - loss: 0.1841 - accuracy: 0.9333 - val_loss: 0.1996 - val_accuracy: 0.9350 - 19s/epoch - 215ms/step\n",
            "Epoch 4/20\n",
            "90/90 - 20s - loss: 0.1774 - accuracy: 0.9389 - val_loss: 0.1284 - val_accuracy: 0.9600 - 20s/epoch - 217ms/step\n",
            "Epoch 5/20\n",
            "90/90 - 19s - loss: 0.1643 - accuracy: 0.9506 - val_loss: 0.1076 - val_accuracy: 0.9500 - 19s/epoch - 215ms/step\n",
            "Epoch 6/20\n",
            "90/90 - 20s - loss: 0.1620 - accuracy: 0.9483 - val_loss: 0.1005 - val_accuracy: 0.9700 - 20s/epoch - 222ms/step\n",
            "Epoch 7/20\n",
            "90/90 - 19s - loss: 0.1472 - accuracy: 0.9467 - val_loss: 0.1309 - val_accuracy: 0.9550 - 19s/epoch - 216ms/step\n",
            "Epoch 8/20\n",
            "90/90 - 19s - loss: 0.1298 - accuracy: 0.9561 - val_loss: 0.1247 - val_accuracy: 0.9500 - 19s/epoch - 215ms/step\n",
            "Epoch 9/20\n",
            "90/90 - 19s - loss: 0.1258 - accuracy: 0.9578 - val_loss: 0.2401 - val_accuracy: 0.9500 - 19s/epoch - 214ms/step\n",
            "Epoch 10/20\n",
            "90/90 - 19s - loss: 0.1374 - accuracy: 0.9550 - val_loss: 0.2404 - val_accuracy: 0.9450 - 19s/epoch - 215ms/step\n",
            "Epoch 11/20\n",
            "90/90 - 20s - loss: 0.1216 - accuracy: 0.9511 - val_loss: 0.1144 - val_accuracy: 0.9650 - 20s/epoch - 223ms/step\n",
            "Epoch 12/20\n",
            "90/90 - 19s - loss: 0.0974 - accuracy: 0.9656 - val_loss: 0.1922 - val_accuracy: 0.9400 - 19s/epoch - 215ms/step\n",
            "Epoch 13/20\n",
            "90/90 - 19s - loss: 0.1411 - accuracy: 0.9600 - val_loss: 0.1198 - val_accuracy: 0.9700 - 19s/epoch - 216ms/step\n",
            "Epoch 14/20\n",
            "90/90 - 20s - loss: 0.1203 - accuracy: 0.9606 - val_loss: 0.1543 - val_accuracy: 0.9550 - 20s/epoch - 218ms/step\n",
            "Epoch 15/20\n",
            "90/90 - 19s - loss: 0.1330 - accuracy: 0.9639 - val_loss: 0.1416 - val_accuracy: 0.9600 - 19s/epoch - 215ms/step\n",
            "Epoch 16/20\n",
            "90/90 - 20s - loss: 0.1172 - accuracy: 0.9589 - val_loss: 0.1989 - val_accuracy: 0.9300 - 20s/epoch - 222ms/step\n",
            "Epoch 17/20\n",
            "90/90 - 19s - loss: 0.1052 - accuracy: 0.9667 - val_loss: 0.1532 - val_accuracy: 0.9650 - 19s/epoch - 216ms/step\n",
            "Epoch 18/20\n",
            "90/90 - 19s - loss: 0.1172 - accuracy: 0.9650 - val_loss: 0.2195 - val_accuracy: 0.9250 - 19s/epoch - 216ms/step\n",
            "Epoch 19/20\n",
            "90/90 - 20s - loss: 0.0833 - accuracy: 0.9756 - val_loss: 0.1727 - val_accuracy: 0.9600 - 20s/epoch - 221ms/step\n",
            "Epoch 20/20\n",
            "90/90 - 20s - loss: 0.1096 - accuracy: 0.9706 - val_loss: 0.1285 - val_accuracy: 0.9650 - 20s/epoch - 221ms/step\n"
          ]
        }
      ]
    }
  ]
}